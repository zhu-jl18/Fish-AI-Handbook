---
title: 微调
description: 轻量与全参微调的路线总览、常见陷阱与资源预算基线。
tab:
  label: 总览
  order: 0
---

## 先定策略（先问清楚再动手）
- 目标：补齐哪类能力？格式跟随谁？（例如客服 QA、代码修复、结构化输出）
- 数据：是否有高质量指令对/对话日志；是否需要过滤敏感/个人信息。
- 资源：可用 GPU 显存与训练时长；交付形态（LoRA / 合并权重 / GGUF）。

## 选择路径
- **LoRA/QLoRA（首选）**：显存友好、迭代快，便于在不同底模间切换。
- **全参 SFT**：仅在大规模高质量数据且可接受更长训练/部署成本时使用。
- **Distillation**：对齐大模型输出，压到 7B–14B 以便推理落地。

## 交付准则
- 推理优先兼容 vLLM 或 llama.cpp（GGUF）；确保有推理基准（latency / tokens/s）。
- 评测：构建最小可用评测集（~200 条），覆盖格式、风格与安全；上线前必跑。
- 版本化：保存 config、commit 哈希与数据快照，便于回滚与复现。
