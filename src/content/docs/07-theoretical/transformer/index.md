---
title: Transformer
description: Transformer 架构 - 现代大语言模型的基础架构
---

## Transformer

Transformer 是一种基于自注意力机制的神经网络架构，是现代大语言模型（如 GPT、BERT）的核心基础。

### 核心特点

- **自注意力机制**：允许模型在处理序列时关注到序列中的所有位置
- **并行计算**：相比 RNN/LSTM 能够更好地利用并行计算资源
- **位置编码**：通过位置编码保留序列中的位置信息

### 经典论文

- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - Transformer 原始论文

### 扩展阅读

- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [Transformer 模型详解](https://zhuanlan.zhihu.com/p/338817680)
