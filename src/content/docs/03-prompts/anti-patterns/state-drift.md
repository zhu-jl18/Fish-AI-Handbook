---
title: 状态漂移与预算滥用：长会话不做重置
description: 长对话累积“过期状态”与噪声，不做“软重置/聚焦”，模型在错误上下文上越走越远。
tab:
  label: 长会话不重置
  order: 50
contributors:
  - codex
---

## 症状
- 长对话反复叠加上下文，越聊越偏；
- 关键阶段没有“再对齐”任务与验收，输出质量起伏大。

## 为什么不好
- 注意力稀释 + Lost in the Middle；
- 过期状态继续影响采样；
- 错误上下文被当真。

## 改法（工程化）
1) 软重置：关键阶段开头“最小重述”（任务/输入/输出结构/约束/DoD）。
2) 结构化记忆：把上轮产物转成“摘要/哈希/schema”，只携带必要事实进入下一轮；
3) 分离短期与长期：短期 scratchpad（思考/推导），长期事实库（RAG 可检索）。

## 好例
```md
本轮最小重述
- 任务：生成 README 模板
- 输入：上轮通过校验的结构化大纲 v1（hash: 3f…）
- 输出结构：{标题/简介/安装/使用/FAQ}
- 约束：字数<300，示例 1 个
- DoD：通过 lint + 链接检查
```

## 模板（可复制）
```md
本轮最小重述（软重置）
- 任务：{…}
- 输入：{上轮产物的摘要/哈希/schema}
- 输出结构：{…}
- 约束：{…}
- DoD：{…}
```

## 评估指标
- Tokens 与费用↓；
- 跑题率↓；
- 上下文相关 bug/误解率↓；
- 中间产物可复验率↑。
